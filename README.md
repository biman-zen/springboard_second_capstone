## Predict Used Vehicle Price Using Scikit-Learn
![image](https://www.usatoday.com/gcdn/media/2018/06/14/USATODAY/usatsports/car-lot-square-e1461855298700.jpg?width=500&height=500&fit=crop&format=pjpg&auto=webp)  
This machine learning project tackles the challenge of predicting used car prices. The original dataset was scraped from Craigslist and Carvana in 2021, available from [Kaggle](https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data). A significant portion of this work focuses on tidying the scraped raw data for modeling. The dataset includes 426,000 rows of values and 26 different columns. Many of the records are missing and require filling in using different methods. To simplify modeling, the final dataset included the top 60 used car models. With the cleaned dataset, four different machine learning algorithms: Linear Regression, Ridge Regression, K-Nearest Neighbors (KNN), and Random Forest Regression were used in conjunction with 5-fold cross-validation to determine model performance. GridSearchCV was used to perform hyperparameter tuning of RF and KNN models to use the optimum paraemters. The top-performing model achieved a cross-validated MAPE of 0.48. For a detailed discussion of the analysis and results, please refer to the "CapstoneII_FinalReport_CLUsedCarDataset.pdf" report.
### How to run the code
The analysis is spread out among 4 jupyter notebooks ending in *.ipynb* extensions. The datasets are stored in *.csv* files under a directory called *data*. The data is read into the notebook using *pd.read_csv('./data/file.csv')*.
1. *CapstoneTwo_CLCardDataset_DataWrangling.ipynb uses original "vehicles.csv"*
2. *CapstoneTwo_CLCardDataset_EDA.ipynb uses original "step1_wrangled_vehicles.csv"*
3. *CapstoneTwo_CLCardDataset_Preprocessing.ipynb uses original "step2_vehicles_eda.csv"*
4. *CapstoneTwo_CLCardDataset_Model.ipynb uses "step3_vehicles_processed.csv"*
